BOILERPLATE LANGCHAIN CODE 

import os
import openai
##### TO KEEP THE API SECRET ##### 
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file
#openai.api_key = os.environ['OPENAI_API_KEY']

##### account for deprecation of LLM model #####
import datetime
# Get the current date
current_date = datetime.datetime.now().date()

# Define the date after which the model should be set to "gpt-3.5-turbo"
target_date = datetime.date(2024, 6, 12)

##### Set the model variable based on the current date #####
if current_date > target_date:
    llm_model = "gpt-3.5-turbo"
else:
    llm_model = "gpt-3.5-turbo-0301"


##### Imports of the memory(s) that i am going to use  #####
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.memory import ConversationSummaryBufferMemory
from langchain.memory import ConversationTokenBufferMemory

#If i am using openAI
from langchain.chat_models import ChatOpenAI

##### Set the memofy and llm model to use  #####
llm = ChatOpenAI(temperature=0.0, model=llm_model)
memory = ConversationBufferMemory()
conversation = ConversationChain(
    llm=llm, 
    memory = memory,
    verbose=True
)

##### To check what we have in memory #####

memory.load_memory_variables({})

##### Create a memory object - We can use one or more types #####
memory = ConversationBufferMemory()
memory = ConversationBufferWindowMemory(k=1)   
memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=50) 
memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)     

##### To add item to memory #####
memory.save_context({"input": "Hi"}, 
                    {"output": "What's up"})